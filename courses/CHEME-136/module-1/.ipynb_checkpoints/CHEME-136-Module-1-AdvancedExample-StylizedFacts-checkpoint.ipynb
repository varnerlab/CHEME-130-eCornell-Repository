{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f74d9e5-c4fb-43c0-90d4-8cf101217358",
   "metadata": {},
   "source": [
    "# Advanced Example: Testing the Stylized Facts of the Generative Model\n",
    "We've already seen that the observed and simulated excess growth rate distributions are heavy-tailed. In this advanced example, we'll explore whether the daily excess growth rate trajectories computed using the Markov model exhibit two other important statistical properties (stylized facts):\n",
    "\n",
    "* __Fact I: Absence of autocorrelations__: The autocorrelations of asset returns are often near-zero, except for very small intraday timescales (on order minutes or less) for which microstructure effects come into play. Given that we are using daily data, we expect the observed and simulated autocorrelations to be near zero. The lack of autocorrelation is consistent with the [random walk hypothesis](https://en.wikipedia.org/wiki/Random_walk_hypothesis).\n",
    "* __Fact II: Volatility clustering__: Different volatility functions display a positive autocorrelation over several time periods, suggesting that high-volatility events tend to cluster in time. In this case, we'll explore the absolute value of the excess growth rate computed using daily data.\n",
    "  \n",
    "### Learning objectives\n",
    "* __Prerequisites__: We begin by loading the daily growth rate Markov model file we saved in the worked example. Using this data, we'll set various variables and constants that are used later.\n",
    "* __Task 1__: Compute the encoded and decoded out-of-sample model predictions. Starting from the stationary distribution $\\bar\\pi$, generate a population of encoded `SPY` growth rate discrete states and then decode these values back to growth rates.\n",
    "* __Task 2__: Compute the stylized facts for the out-of-sample observed and simulated growth rate dataset.\n",
    "    * `TODO`: Autocorrelation of the out-of-sample dataset\n",
    "    * `TODO`: Volatility clustering of the out-of-sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebcabc-b12b-446a-a4d6-1498e32257b2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including the `Include.jl` file. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our lab problem.\n",
    "* For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/) and the [VLQuantitativeFinancePackage.jl documentation](https://github.com/varnerlab/VLQuantitativeFinancePackage.jl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbaff9e7-7134-463e-9efd-1aaffa44fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLQuantitativeFinancePackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLQuantitativeFinancePackage.jl.git`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81489295-44e4-4e7e-8035-39ccef14770d",
   "metadata": {},
   "source": [
    "## Prerequisites: Load daily HMM model file\n",
    "Let's begin by loading the [HDF5 encoded saved file](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) generated in the worked example using [a `load(...)`  method exported by the JLD2.jl package](https://github.com/JuliaIO/JLD2.jl). First, we specify the path to the saved file in the `path_to_save_file::String` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c65329-1d95-4448-b1dd-0431755e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"SPY\"\n",
    "path_to_save_file = joinpath(_PATH_TO_DATA,\"HMM-$(ticker)-daily-aggregate.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2fd4d-1a92-4461-b9e6-f0920019dc6b",
   "metadata": {},
   "source": [
    "then we [call the `load(...)` method exported by the JLD2.jl package](https://github.com/JuliaIO/JLD2.jl), which reads the binary saved file and returns the saved data as a dictionary; we assign the data to the `saved_state_dict::Dict{String, Any}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbdd294-0ff2-4d19-ac23-d12f458a9c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 5 entries:\n",
       "  \"insampledataset\"    => [1.51294, 1.10337, 0.783659, 0.74692, -0.651317, 1.28…\n",
       "  \"stationary\"         => Categorical{Float64, Vector{Float64}}(…\n",
       "  \"model\"              => MyHiddenMarkovModel([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  ……\n",
       "  \"decode\"             => Dict{Int64, Normal}(5=>Normal{Float64}(μ=-3.5653, σ=0…\n",
       "  \"outofsampledataset\" => [3.06408, -3.55485, -3.04269, -5.37542, -1.35013, -1.…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_state_dict = load(path_to_save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af62904-7a66-433f-b7ee-a66cfb6ec9b6",
   "metadata": {},
   "source": [
    "The `saved_state_dict::Dict{String, Any}` dictionary holds the out-of-sample dataset (`SPY` growth rate data, not used for training) in the `outofsampledataset` key. We retrieve the out-of-sample data and store it in the `out_of_sample_dataset::Array{Float64,1}` variable. The length of the `out_of_sample_dataset::Array{Float64,1}` array is the number of test examples we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3ade65-3c11-49e0-b31a-691c37609602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467-element Vector{Float64}:\n",
       "  3.064075246029285\n",
       " -3.554849634227477\n",
       " -3.0426929891956753\n",
       " -5.375424627605836\n",
       " -1.3501276473577843\n",
       " -1.5605940652938788\n",
       " -4.806425661497439\n",
       "  6.26107604235329\n",
       "  0.44382036758096866\n",
       "  3.1480968799843168\n",
       " -6.152874401787635\n",
       " -3.678107580537128\n",
       " -2.185498251756967\n",
       "  ⋮\n",
       " -0.46407701702660653\n",
       " -0.13948780347442888\n",
       "  0.9060279176165984\n",
       "  1.5886628608286195\n",
       "  0.6856283645585958\n",
       " -2.393298385192234\n",
       "  0.9267625992892551\n",
       "  2.0955659969498117\n",
       " -0.15429197151137425\n",
       " -1.6983801647597287\n",
       "  2.1267483471553437\n",
       "  0.5638387917487099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_sample_dataset = saved_state_dict[\"outofsampledataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6eca86-0aae-4a37-8484-85b903cba0c0",
   "metadata": {},
   "source": [
    "Next, we get [the `MyHiddenMarkovModel` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/markov/#VLQuantitativeFinancePackage.MyHiddenMarkovModel) that we constructed in the worked example from the `saved_state_dict::Dict{String, Any}` dictionary using the `model::String` key. We save the Markov model in the `model::MyHiddenMarkovModel` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ab9d2e-6dcc-46c5-9600-90727c4ac428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = saved_state_dict[\"model\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2161e71-2864-48cc-8342-4fede045198b",
   "metadata": {},
   "source": [
    "## Task 1: Compute the decoded out-of-sample model prediction\n",
    "In this task, you will sample the `model::MyHiddenMarkovModel` instance and will generate a family of encoded state sequences, i.e., a series of discrete state values $s_{j}\\in\\mathcal{S}$ where each sample trajectory starts from a draw from the stationary distribution $\\bar\\pi$. \n",
    "* We computed the stationary distribution $\\bar\\pi$ in the worked example; here we access the saved value from the `saved_state_dict::Dict{String, Any}` dictionary using the `stationary::String` key. We save the stationary distribution in the `π̄::Categorical{Float64, Vector{Float64}}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24534da-d760-4f15-959b-eeb4ee0e511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "π̄ = saved_state_dict[\"stationary\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef8723-d2d2-4723-bbcf-425a9a21e348",
   "metadata": {},
   "source": [
    "Let's now generate the `encoded_archive::Array{Int64,2}` array, which holds `number_of_paths` discrete state trajectories each of length `number_of_steps` by using some fantastic syntactic-sugar in Julia:\n",
    "* Internally, we've created a function `(m::MyHiddenMarkovModel)(start::Int64, steps::Int64) = _simulate(m, start, steps)` which provides a short-cut syntax to sampling the `model::MyHiddenMarkovModel` instance, where the sampling logic is encoded in the private `_simulate(m, start, steps)` function.\n",
    "\n",
    "After declaring how many sample paths we want (specified in the `number_of_paths::Int64` variable), how many steps we are going to take (specified in the `number_of_steps::Int64` variable), and initializing the `encoded_archive::Array{Int64,2}` array which will store the model samples, we populate the sample array using a nested [`for-loop`](https://docs.julialang.org/en/v1/manual/variables-and-scoping/#Loops-and-Comprehensions):\n",
    "* The outer loop iterates over the sample paths, the `i` index, where we generate an initial state for each sample path by drawing a sample from the $\\bar\\pi$ distribution. We save the initial state in the `start_state::Int64` variable.\n",
    "* The inner loop iterates over the time steps in each sample path, the `j` index, where we generate a `number_of_steps`$\\times$ `1` array of discrete state values $s\\in\\mathcal{S}$ in the `tmp::Array{Int64,1}` array. We then add the values of the `tmp` array to the `encoded_archive` array, where the time steps are on the rows and the sample paths are on the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3a14f0-f257-4463-9954-e3642de8a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467×10000 Matrix{Int64}:\n",
       " 21  26  14  49  19  68  35  24  22  …   3  46  36  46   5  49  56  32  42\n",
       " 63  24  71  62  39  75  19  73   7      1  26  18   2  46  21  69  15  75\n",
       " 34   2  49  49  49  64  33  63  74     80   1  29  19   9  53  32  72  54\n",
       " 51   1  36  39  24  35  28  46  63     80  72  49  30  22  62  12  10  64\n",
       "  6   3  57  49  25  25  63  70  46     43  49  50  44  46  28  53   1  53\n",
       " 51  55  37  47  59  67  71  58  22  …  34  36  56  34  56  23  62  28  10\n",
       " 43  51  46  63  27  76  65  74   1     26   5  77  36  61  61  56  10   2\n",
       " 25  49  46  54  25  32  36  29  75     24   3  53  38  64  33  61  24  10\n",
       "  9  36   9  69  52  76   9  27  63     13   5  52  55  27  20  74   4  24\n",
       " 22  39  38  32  49  36  18   8  69      1  10  52  14  58   4  31  65  58\n",
       " 46  54  42  79  16  58   8  28  49  …  72  40  52   3  57   9  46  24  21\n",
       " 45  37  53  70  72   4  61  61  21     63  31  13  55  36  38  50  14  21\n",
       " 62  45  10  16  24   6  68  65  21     23  57  72  75  18  21  46  32  56\n",
       "  ⋮                   ⋮              ⋱                   ⋮              \n",
       " 58  46  65  21  28  16  21   1  22  …  46  75  74  33   8  44  40  36   5\n",
       " 25  56  58  21  17  54  14  28  59     26  21   2  33  57  54  41  78  80\n",
       " 71  41  61  26   5   1  57  17  26     54  52   1  33  35  15  59  52  80\n",
       " 47  59  33   1  62   5  37   5  50      1  49  20  20   8  45  50  25  59\n",
       " 55  37  20   3  62   4  46  78   9     16  41   6  11   4  13  56   9  11\n",
       " 65  46   6   3  52   6  46  75  38  …  72  59  72  64  65   1  61  76  78\n",
       " 73  26  51   7  11  49  22  14  38     37  65  28  66  40  74  57  16  48\n",
       " 60  16   6   5  66  52   6  57  72     48  49  53  57  38   8  28  72  64\n",
       " 35  21  33  62  17  52  55  61  56     71  16  38  52  20  33  61  71  66\n",
       " 25  66  62  63  45  53  51  64   4     49   6  51  20   4  45  62  65  17\n",
       " 24  17  55  69  21  10  23  19  65  …  50  49  17  13  52  70  63  48  72\n",
       " 73  10  44  26  52  43  41  63  12     69  36  36   1  32  78  22  15  56"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_paths = 10000;\n",
    "number_of_steps = length(out_of_sample_dataset); # average number of trading days per year\n",
    "encoded_archive = Array{Int64,2}(undef, number_of_steps, number_of_paths);\n",
    "for i ∈ 1:number_of_paths\n",
    "    start_state = rand(π̄);\n",
    "    tmp = model(start_state, number_of_steps) # generates state sequence of length number_of_steps\n",
    "    for j ∈ 1:number_of_steps\n",
    "        encoded_archive[j,i] = tmp[j]\n",
    "    end\n",
    "end\n",
    "encoded_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e0621-40c0-4899-a000-783f8c2c5e57",
   "metadata": {},
   "source": [
    "### TODO: Compute the decoded simulation array\n",
    "Now that we have populated the `encoded_archive::Array{Int64,2}` array, which holds the hidden discrete states, we need to convert the discrete states back into floating point excess growth rate values. We do this using a _decoding model_ which transforms the encoded values into growth rate values. We generated (and persisted) the _decode model_ in the worked example. \n",
    "* Load the _decode model_ from the `saved_state_dict::Dict{String, Any}` dictionary using the `decode::String` key. We save the _decode model_ in the `decode_distribution_model::Dict{Int64, Normal}` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468c2ed9-7b29-4742-8d4a-c1451c83c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_distribution_model = saved_state_dict[\"decode\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e1f00-3307-432d-bfa5-40fe5b1bba91",
   "metadata": {},
   "source": [
    "The `decode_distribution_model::Dict{Int64, Normal}` dictionary holds a [Normal distribution model](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Normal) for each state $s\\in\\mathcal{S}$. We sample these distributions to generate a value of the excess growth rate that corresponds to a particular discrete state `s.` Thus, to decode the encoded sample array, we iterate through the `encoded_archive` array and sample the _decode model_ that is associated with $s\\in\\mathcal{S}$, and then save that value in the `out_of_sample_decoded_archive::Array{Float64,2}` array using a nested [`for-loop`](https://docs.julialang.org/en/v1/manual/variables-and-scoping/#Loops-and-Comprehensions):\n",
    "* The outer loop iterates over the sample paths, the `i` index, while the inner loop, the `j` index, iterates over the time steps. Inside the inner loop, we select a state `s,` access the corresponding _Normal decode model_ for state `s,` (the `j,i` element of the `encoded_archive`) and sample that model [using a `rand(...)` method exported by the  Distributions.jl package](https://juliastats.org/Distributions.jl/stable/univariate/#Base.rand-Tuple{AbstractRNG,%20UnivariateDistribution}) in combination with the [Julia pipe `|>` operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping).\n",
    "\n",
    "The `out_of_sample_decoded_archive::Array{Float64,2}` holds values for the excess growth rate for each time step and sample path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e690702f-724f-4035-a412-9fa2c3b52c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467×10000 Matrix{Float64}:\n",
       " -0.96446     -0.610385   -1.68615    …   1.01267   -0.219844    0.252593\n",
       "  1.58424     -0.749799    2.62163        2.34647   -1.55404     3.62137\n",
       " -0.114227    -5.80182     0.604625      -0.234003   2.9104      0.906497\n",
       "  0.731037   -10.346      -0.0268181     -1.96795   -2.30835     1.73239\n",
       " -3.22888     -4.50703     1.15351        0.835942  -9.24108     0.843543\n",
       "  0.719497     0.959144    0.0362623  …   1.57112   -0.476014   -2.24399\n",
       "  0.309726     0.701321    0.48194        1.01681   -2.3028     -5.25179\n",
       " -0.671881     0.584244    0.443861       1.41568   -0.7717     -2.28655\n",
       " -2.5126      -0.0365356  -2.53354        3.28582   -4.28076    -0.769678\n",
       " -0.864302     0.125412    0.0811126     -0.314089   1.84862     1.20175\n",
       "  0.439941     0.90849     0.261959   …   0.462903  -0.721871   -0.975237\n",
       "  0.39287      0.0247702   0.818709       0.660652  -1.70459    -0.924682\n",
       "  1.54676      0.398731   -2.39121        0.47207   -0.240567    1.03145\n",
       "  ⋮                                   ⋱                         \n",
       "  1.18885      0.441515    1.80803    …   0.166024  -0.0228773  -3.5911\n",
       " -0.651861     1.03182     1.19035        0.212356   5.2159      5.93261\n",
       "  2.69062      0.193024    1.37747        1.2806     0.766889    6.02515\n",
       "  0.494332     1.27256    -0.166233       0.670673  -0.632098    1.26721\n",
       "  0.958017     0.0344558  -1.048          1.0323    -2.57658    -2.12109\n",
       "  1.84731      0.414114   -3.20787    …   1.43777    4.10312     4.74627\n",
       "  2.9834      -0.596125    0.718649       1.12551   -1.4394      0.510261\n",
       "  1.32737     -1.47949    -3.19313       -0.484212   2.8437      1.7328\n",
       " -0.0741636   -0.940004   -0.176941       1.37462    2.65461     1.98618\n",
       " -0.63763      1.93961     1.51284        1.53253    1.76238    -1.32354\n",
       " -0.792196    -1.34586     1.00135    …   1.62379    0.544564    2.83689\n",
       "  3.14641     -2.31062     0.329753      -0.887932  -1.5162      1.03251"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_sample_decoded_archive = Array{Float64,2}(undef, number_of_steps, number_of_paths);\n",
    "for i ∈ 1:number_of_paths\n",
    "    for j ∈ 1:number_of_steps\n",
    "        s = encoded_archive[j,i];\n",
    "        out_of_sample_decoded_archive[j,i] =  decode_distribution_model[s] |> d -> rand(d)\n",
    "    end\n",
    "end\n",
    "out_of_sample_decoded_archive # actual excess growth value (not internal state variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b551997b-16c7-441d-9866-0145953104a7",
   "metadata": {},
   "source": [
    "## Task 2: Stylized facts for out-of-sample dataset\n",
    "This task compares the stylized facts for the observed out-of-sample and simulated excess growth datasets. In particular, we'll look at two stylized facts, namely, the autocorrelation of the excess growth rate and the volatility clustering, i.e., the autocorrelation of the absolute value of the excess growth rate.\n",
    "\n",
    "### TODO: Autocorrelation of the out-of-sample dataset\n",
    "Let's look at the [autocorrelation as a function of the time lag](https://en.wikipedia.org/wiki/Autocorrelation) for the data in the `out_of_sample_dataset` and a randomly selected trajectory from the `out_of_sample_decoded_archive` array. \n",
    "\n",
    "#### Summary\n",
    "`Unhide` the code block below to see how we computed and plotted the [autocorrelation function](https://en.wikipedia.org/wiki/Autocorrelation) for the simulated and observed out-of-sample dataset.\n",
    "* The [random walk hypothesis](https://en.wikipedia.org/wiki/Random_walk_hypothesis) suggests that for lags greater than `1`, the autocorrelation of the return should be zero. We tested this idea using the observed out-of-sample growth rates in the `out_of_sample_dataset::Array{Float64,1}` array and the simulated growth rates in the `out_of_sample_decoded_archive` array.\n",
    "* The observed (orange) and simulated (blue) excess growth rates show a near-zero autocorrelation at a 99% confidence level as a function of the lag (day), with the exception of a few lags in the first hundred days.\n",
    "* Although both the data and the model show a few violations of the autocorrelation hypothesis, these violations are weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39be01b3-8f7c-48d6-9f47-2065e87ca352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/jeffreyvarner/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/figs/Fig-Autocorrelation-HMM-GenModel-SPY.pdf\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, \n",
    "    #     fg_legend = :transparent\n",
    "\n",
    "    # generate a random index -\n",
    "    random_index = rand(1:number_of_paths);\n",
    "    \n",
    "    plot(autocor(out_of_sample_dataset, (1:(number_of_steps - 1) |> collect)), label=\"Observed\", lw=2, c=:red, \n",
    "        bg=:black, background_color_outside=\"black\", framestyle = :box, fg_legend = :transparent, \n",
    "        foreground_color_axis=:white, foreground_color_grid=\"white\",\n",
    "        foreground_color_border = :white, legend_font_color = :white, foreground_color=:black, foreground_color_text=:white,\n",
    "        yguidefontcolor=:white,xguidefontcolor=:white, linetype=:steppost)\n",
    "    plot!(autocor(out_of_sample_decoded_archive[:,random_index], (1:(number_of_steps - 1) |> collect)), c=:blue, \n",
    "        label=\"Simulated (i = $(random_index))\", linetype=:steppost)\n",
    "    \n",
    "    LINE = (2.576/sqrt(number_of_steps))*ones(number_of_steps-1);\n",
    "    plot!(LINE, label=\"99% confidence\", lw=2, c=:white, ls=:dash)\n",
    "    plot!(-LINE, label=\"\", lw=2, c=:white, ls=:dash)\n",
    "    xlabel!(\"Lag (trading day)\", fontsize=18)\n",
    "    ylabel!(\"Autocorrelation Growth Rate\", fontsize=18)\n",
    "\n",
    "    # uncomment me to save to file -\n",
    "    # savefig(joinpath(_PATH_TO_FIGS, \"Fig-Autocorrelation-HMM-GenModel-$(ticker).pdf\"));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714acb9b-d674-4135-81ba-8b425d322846",
   "metadata": {},
   "source": [
    "### TODO: Volatility clustering of the out-of-sample dataset\n",
    "Next, let's consider volatility clustering. Volatility clustering is determined by examining the autocorrelation of the absolute values of the excess growth rate for different lag values. In actual data, we expect a positive absolute autocorrelation for short lags. Volatility clustering indicates that periods of high volatility, such as significant changes in returns, tend to occur close together in time.\n",
    "\n",
    "### Summary\n",
    "`Unhide` the code block below to see how we computed and plotted the [autocorrelation function](https://en.wikipedia.org/wiki/Autocorrelation) for the absolute values of the simulated and observed out-of-sample excess growth rates.\n",
    "* The observed out-of-sample dataset (orange line) shows a positive autocorrelation for lags less than approximately `10 days` at a 99% confidence level. This suggests the market has a memory of approximately 10 days or less following large disruptions.\n",
    "* The excess growth rate trajectories produced by the Markov model (blue line) don't show volatility clustering; thus, this model (at least as it's currently implemented) will not capture the clustering of high-volatility events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c680ec5-c8bd-4089-a45f-b1f5d247efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/jeffreyvarner/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/figs/Fig-VolClustering-HMM-GenModel-SPY.pdf\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # generate a random index -\n",
    "    random_index = rand(1:number_of_paths);\n",
    "    \n",
    "    plot(autocor(abs.(out_of_sample_dataset), (1:(number_of_steps - 1) |> collect)), label=\"Observed\", lw=2, c=:red, \n",
    "        bg=:black, background_color_outside=\"black\", framestyle = :box, fg_legend = :transparent, \n",
    "        foreground_color_axis=:white, foreground_color_grid=\"white\",\n",
    "        foreground_color_border = :white, legend_font_color = :white, foreground_color=:black, foreground_color_text=:white,\n",
    "        yguidefontcolor=:white,xguidefontcolor=:white, linetype=:steppost)\n",
    "    plot!(autocor(abs.(out_of_sample_decoded_archive[:,random_index]), (1:(number_of_steps - 1) |> collect)), c=:blue, \n",
    "        label=\"Simulated (i = $(random_index))\", linetype=:steppost)\n",
    "    \n",
    "    LINE = (2.576/sqrt(number_of_steps))*ones(number_of_steps-1);\n",
    "    plot!(LINE, label=\"99% confidence\", lw=2, c=:white, ls=:dash)\n",
    "    plot!(-LINE, label=\"\", lw=2, c=:white, ls=:dash)\n",
    "    xlabel!(\"Lag (trading day)\", fontsize=18)\n",
    "    ylabel!(\"Autocorrelation abs(Growth rate)\", fontsize=18)\n",
    "\n",
    "    # uncomment me to save to file -\n",
    "    # savefig(joinpath(_PATH_TO_FIGS, \"Fig-VolClustering-HMM-GenModel-$(ticker).pdf\"));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65248960-fcc5-4b2e-93f1-341de07fa737",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team. \n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. You should decide solely based on your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
