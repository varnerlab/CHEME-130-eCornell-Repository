{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6863fe8-f58f-4503-8a3e-aec882862964",
   "metadata": {},
   "source": [
    "# Project: Calculating out-of-sample Markov Model Performance\n",
    "We will build on our previous discussions about Markov models during this project. Students will evaluate the out-of-sample performance of the daily growth rate model we developed in the worked example. We anticipate that the out-of-sample performance will be inferior to the in-sample training data. Toward this hypothesis, we will examine various model performance metrics and assess the extent of the performance degradation.\n",
    "\n",
    "### Learning objectives\n",
    "* __Prerequisites__: We begin by loading the daily growth rate Markov model file we saved in the worked example. Using this data, we'll set various variables and constants that are used later.\n",
    "* __Task 1__: Compute the encoded out-of-sample model prediction. Starting from the stationary distribution $\\bar\\pi$, generate a population of encoded `SPY` growth rate samples\n",
    "* __Task 2__: Decode the out-of-sample model prediction. This will take the samples from Task 1 and transform them from discrete internal state variables to floating point values for the daily excess growth rate.\n",
    "* __Task 3__: How good is the out-of-sample model prediction? Finally, we'll compare the properties of the out-of-sample prediction with the observed out-of-sample `SPY` growth rate sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92fb57-f2e3-4f73-88fd-6b9065a14676",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including the `Include.jl` file. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our lab problem.\n",
    "* For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/) and the [VLQuantitativeFinancePackage.jl documentation](https://github.com/varnerlab/VLQuantitativeFinancePackage.jl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3b9048-4b2f-4eeb-910f-803608c1500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d103f62-7f83-4184-b9b4-918797eccd26",
   "metadata": {},
   "source": [
    "## Prerequisites: Load daily HMM model file\n",
    "Let's begin by loading the [HDF5 encoded saved file](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) generated in the worked example using [a `load(...)`  method exported by the JLD2.jl package](https://github.com/JuliaIO/JLD2.jl). First, we specify the path to the saved file in the `path_to_save_file::String` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0f60b9-e0d1-4eae-81ce-ecc44944f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"SPY\"\n",
    "path_to_save_file = joinpath(_PATH_TO_DATA,\"HMM-$(ticker)-daily-aggregate.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3de16d-0318-4b93-aefc-e338ed1f240e",
   "metadata": {},
   "source": [
    "then we [call the `load(...)` method exported by the JLD2.jl package](https://github.com/JuliaIO/JLD2.jl), which reads the binary saved file and returns the saved data as a dictionary; we assign the data to the `saved_state_dict::Dict{String, Any}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acb6630-3943-4755-81d8-9b7b0bb58cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 5 entries:\n",
       "  \"insampledataset\"    => [1.51294, 1.10337, 0.783659, 0.74692, -0.651317, 1.28…\n",
       "  \"stationary\"         => Categorical{Float64, Vector{Float64}}(…\n",
       "  \"model\"              => MyHiddenMarkovModel([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  ……\n",
       "  \"decode\"             => Dict{Int64, Normal}(5=>Normal{Float64}(μ=-3.5653, σ=0…\n",
       "  \"outofsampledataset\" => [3.06408, -3.55485, -3.04269, -5.37542, -1.35013, -1.…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_state_dict = load(path_to_save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db6687-7377-4169-97f2-fcf6030127dd",
   "metadata": {},
   "source": [
    "The `saved_state_dict::Dict{String, Any}` dictionary holds the out-of-sample dataset (`SPY` growth rate data, not used for training) in the `outofsampledataset` key. We retrieve the out-of-sample data and store it in the `out_of_sample_dataset::Array{Float64,1}` variable. The length of the `out_of_sample_dataset::Array{Float64,1}` array is the number of test examples we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd63769-9d3a-4307-92ef-4a43acb48df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467-element Vector{Float64}:\n",
       "  3.064075246029285\n",
       " -3.554849634227477\n",
       " -3.0426929891956753\n",
       " -5.375424627605836\n",
       " -1.3501276473577843\n",
       " -1.5605940652938788\n",
       " -4.806425661497439\n",
       "  6.26107604235329\n",
       "  0.44382036758096866\n",
       "  3.1480968799843168\n",
       " -6.152874401787635\n",
       " -3.678107580537128\n",
       " -2.185498251756967\n",
       "  ⋮\n",
       " -0.46407701702660653\n",
       " -0.13948780347442888\n",
       "  0.9060279176165984\n",
       "  1.5886628608286195\n",
       "  0.6856283645585958\n",
       " -2.393298385192234\n",
       "  0.9267625992892551\n",
       "  2.0955659969498117\n",
       " -0.15429197151137425\n",
       " -1.6983801647597287\n",
       "  2.1267483471553437\n",
       "  0.5638387917487099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_sample_dataset = saved_state_dict[\"outofsampledataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a16d3d-43e9-4e66-883f-c79d8139d063",
   "metadata": {},
   "source": [
    "Next, we get [the `MyHiddenMarkovModel` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/markov/#VLQuantitativeFinancePackage.MyHiddenMarkovModel) that we constructed in the worked example from the `saved_state_dict::Dict{String, Any}` dictionary using the `model::String` key. We save the Markov model in the `model::MyHiddenMarkovModel` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf6ac66c-df22-41dd-a971-3fccf7311a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = saved_state_dict[\"model\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de21539-4f87-474c-ba6a-49b8fd0c7f12",
   "metadata": {},
   "source": [
    "## Task 1: Compute the encoded out-of-sample model prediction\n",
    "In this task, you will sample the `model::MyHiddenMarkovModel` instance and will generate a family of encoded state sequences, i.e., a series of discrete state values $s_{j}\\in\\mathcal{S}$ where each sample trajectory starts from a draw from the stationary distribution $\\bar\\pi$. \n",
    "* We computed the stationary distribution $\\bar\\pi$ in the worked example; here we access the saved value from the `saved_state_dict::Dict{String, Any}` dictionary using the `stationary::String` key. We save the stationary distribution in the `π̄::Categorical{Float64, Vector{Float64}}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a37470-97f0-45b9-84e4-9b89580c3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "π̄ = saved_state_dict[\"stationary\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce79277f-06ce-4f13-be9f-45900bc7cb69",
   "metadata": {},
   "source": [
    "Let's now generate the `encoded_archive::Array{Int64,2}` array, which holds `number_of_paths` discrete state trajectories each of length `number_of_steps` by using some fantastic syntactic-sugar in Julia:\n",
    "* Internally, we've created a function `(m::MyHiddenMarkovModel)(start::Int64, steps::Int64) = _simulate(m, start, steps)` which provides a short-cut syntax to sampling the `model::MyHiddenMarkovModel` instance, where the sampling logic is encoded in the private `_simulate(m, start, steps)` function.\n",
    "\n",
    "After declaring how many sample paths we want (specified in the `number_of_paths::Int64` variable), how many steps we are going to take (specified in the `number_of_steps::Int64` variable), and initializing the `encoded_archive::Array{Int64,2}` array which will store the model samples, we populate the sample array using a nested [`for-loop`](https://docs.julialang.org/en/v1/manual/variables-and-scoping/#Loops-and-Comprehensions):\n",
    "* The outer loop iterates over the sample paths, the `i` index, where we generate an initial state for each sample path by drawing a sample from the $\\bar\\pi$ distribution. We save the initial state in the `start_state::Int64` variable.\n",
    "* The inner loop iterates over the time steps in each sample path, the `j` index, where we generate a `number_of_steps`$\\times$ `1` array of discrete state values $s\\in\\mathcal{S}$ in the `tmp::Array{Int64,1}` array. We then add the values of the `tmp` array to the `encoded_archive` array, where the time steps are on the rows and the sample paths are on the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e98139-4f32-484a-9a32-2df789ee15e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467×10000 Matrix{Int64}:\n",
       " 23  64  27  80  63  37  25  17   4  …  52  34   6  39  34   8   2  21   9\n",
       " 15  34  76  80  73  21  24  35   9     49  40  72  54  35  28   3  26  76\n",
       " 64   8  78   4  68  66  25  16   9     36  26  78  52  35  36   1  19  69\n",
       " 65   4  75  45  26  17  52  73  71     46  54  54  52  19   5  74  55  49\n",
       " 35  52  62  27  28  45  20  11   6     46  15  65  13   8  75  68  29  39\n",
       " 42  49  62  76   5  62   4  51  33  …  26  72  20   1  36  43  75  47  29\n",
       " 31  62  49  70  78   7  65  17  10     24  28   1  51  42  51  62  53  49\n",
       " 36  62   5  68  36   5  45  45  40      2  54  12  43  24  63  52  36  31\n",
       " 42  62  54  39   7   3   3  12  43     53  65  67  41  17   8  74  18  34\n",
       " 59  69  46  57   8   5  48  65  28     52  12  55  72  45  69   8  29  36\n",
       " 11  72  45  61  69  38  71  12  53  …  61  25  17  78  42  32   8  59  57\n",
       " 64   1  56  25  76  34   6  25  49     33  67  30  52  67  56  69  73  35\n",
       " 19   3  41  31  69  23  22  71  36     22  53  44  33  47  68  47  60  48\n",
       "  ⋮                   ⋮              ⋱                   ⋮              \n",
       " 13  49  52  22  28  70  58  32  38  …  58  32  10   1  54  59  63  76  39\n",
       " 72  37  20  50   5  32  21  49  45     18  49   1  37  19  73  34  16  57\n",
       " 37  38  13   9  35  49  56  45   5      8  62  69  37  56  15  51  36  33\n",
       " 46  14   2  71  53  62   4   3  38     28  56  52  61  58  65  21   7  35\n",
       " 26  11   1  58  49  52  65  70  20     58  48  63  38  58  24  53  23   8\n",
       " 20  63  74  61  45  33  47  58   6  …  53  44  69  38  61   2  10  67  33\n",
       "  1  34  64  62  62  20  63  34  49     49  54  22  33  62   1   9  27  33\n",
       " 12   4  70   7  57  20  34  26  45     36  34  36  35  28  64  17  24  67\n",
       " 27  65  67   8  36   1  27  60  70     78  23  65  45  63  70  28   2   7\n",
       " 58  48  58  61  58  69  46  76  55     19  41  40  51  71  55  53  58  34\n",
       " 57  13  53  74  24  72  40  51  59  …  63  18  37   8   7  59  32  74  45\n",
       " 31   2  38  63  36   1  34  43  65      7  37  33   4  23  51  56  68  68"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_paths = 10000;\n",
    "number_of_steps = length(out_of_sample_dataset); # average number of trading days per year\n",
    "encoded_archive = Array{Int64,2}(undef, number_of_steps, number_of_paths);\n",
    "for i ∈ 1:number_of_paths\n",
    "    start_state = rand(π̄);\n",
    "    tmp = model(start_state, number_of_steps) # generates state sequence of length number_of_steps\n",
    "    for j ∈ 1:number_of_steps\n",
    "        encoded_archive[j,i] = tmp[j]\n",
    "    end\n",
    "end\n",
    "encoded_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f4f10-562b-4cee-9161-b5b9e06d6f28",
   "metadata": {},
   "source": [
    "## Task 2: Decode the out-of-sample model prediction\n",
    "Now that we have populated the `encoded_archive::Array{Int64,2}` array, which holds the hidden discrete states, we need to convert the discrete states back into floating point excess growth rate values. We do this using a _decoding model_ which transforms the encoded values into growth rate values. We generated (and persisted) the _decode model_ in the worked example. \n",
    "* Load the _decode model_ from the `saved_state_dict::Dict{String, Any}` dictionary using the `decode::String` key. We save the _decode model_ in the `decode_distribution_model::Dict{Int64, Normal}` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebd2e2f6-9eda-4065-94b2-2725fe775e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_distribution_model = saved_state_dict[\"decode\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d8b86-9e2a-48ee-b373-8d2104a03fd9",
   "metadata": {},
   "source": [
    "The `decode_distribution_model::Dict{Int64, Normal}` dictionary holds a [Normal distribution model](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Normal) for each state $s\\in\\mathcal{S}$. We sample these distributions to generate a value of the excess growth rate that corresponds to a particular discrete state `s.` Thus, to decode the encoded sample array, we iterate through the `encoded_archive` array and sample the _decode model_ that is associated with $s\\in\\mathcal{S}$, and then save that value in the `out_of_sample_decoded_archive::Array{Float64,2}` array using a nested [`for-loop`](https://docs.julialang.org/en/v1/manual/variables-and-scoping/#Loops-and-Comprehensions):\n",
    "* The outer loop iterates over the sample paths, the `i` index, while the inner loop, the `j` index, iterates over the time steps. Inside the inner loop, we select a state `s,` access the corresponding _Normal decode model_ for state `s,` (the `j,i` element of the `encoded_archive`) and sample that model [using a `rand(...)` method exported by the  Distributions.jl package](https://juliastats.org/Distributions.jl/stable/univariate/#Base.rand-Tuple{AbstractRNG,%20UnivariateDistribution}) in combination with the [Julia pipe `|>` operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping).\n",
    "\n",
    "The `out_of_sample_decoded_archive::Array{Float64,2}` holds values for the excess growth rate for each time step and sample path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef565b5-3d87-4080-9a16-3d05dda885c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467×10000 Matrix{Float64}:\n",
       " -0.793126    1.77306    -0.507813   …  -5.66098   -0.960743   -2.4409\n",
       " -1.5491     -0.105438    3.6964        -4.88401   -0.600838    3.91522\n",
       "  1.70256    -2.66358     4.97618       -9.19803   -1.15674     2.36847\n",
       "  1.8588     -4.03792     3.54061        3.30429    0.966387    0.581551\n",
       " -0.0615165   0.783604    1.52253        2.15006   -0.393218    0.126118\n",
       "  0.258329    0.59137     1.57521    …   3.6048     0.50988    -0.397743\n",
       " -0.271802    1.50807     0.567494       1.56462    0.856204    0.610975\n",
       " -0.0430345   1.50423    -3.66407        0.774676  -0.0344235  -0.30249\n",
       "  0.244004    1.50036     0.894929       3.36044   -1.25504    -0.139702\n",
       "  1.29433     2.3562      0.446125      -2.63253   -0.369969   -0.0228818\n",
       " -2.10365     2.86207     0.394486   …  -2.6673     1.27928     1.08705\n",
       "  1.71215    -8.89085     1.04197        2.38996    3.07604    -0.0623919\n",
       " -1.19689    -5.2559      0.197908       0.490855   1.32135     0.527861\n",
       "  ⋮                                  ⋱                         \n",
       " -1.80456     0.598882    0.762541   …   1.61289    3.79388     0.130242\n",
       "  2.95331     0.0263344  -1.04527       -0.117869  -1.46037     1.13096\n",
       "  0.0211851   0.085036   -1.78984        0.717422  -0.0238905  -0.18847\n",
       "  0.46225    -1.69904    -5.59249       -0.982196  -2.84458    -0.0570255\n",
       " -0.588616   -2.13198    -4.60819        0.807987  -0.792704   -2.75041\n",
       " -1.01987     1.64013     3.41227    …  -2.28524    2.10246    -0.190281\n",
       " -4.99273    -0.122466    1.74974       -2.35216   -0.49156    -0.171742\n",
       " -1.98833    -3.81659     2.39673       -1.31876   -0.77328     2.07955\n",
       " -0.508621    1.80066     2.03286       -0.473703  -5.71261    -3.00179\n",
       "  1.19562     0.507779    1.22813        0.853304   1.20858    -0.128497\n",
       "  1.11727    -1.91749     0.851484   …  -0.24115    3.32544     0.376267\n",
       " -0.299205   -5.06899     0.0910479      1.03839    2.26649     2.24703"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_sample_decoded_archive = Array{Float64,2}(undef, number_of_steps, number_of_paths);\n",
    "for i ∈ 1:number_of_paths\n",
    "    for j ∈ 1:number_of_steps\n",
    "        s = encoded_archive[j,i];\n",
    "        out_of_sample_decoded_archive[j,i] =  decode_distribution_model[s] |> d -> rand(d)\n",
    "    end\n",
    "end\n",
    "out_of_sample_decoded_archive # actual excess growth value (not internal state variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc43a68-351b-411c-838c-770b656b0c5e",
   "metadata": {},
   "source": [
    "## Task 3: How good is the out-of-sample model prediction?\n",
    "Now that we have populated the `out_of_sample_decoded_archive::Array{Float64,2}` array with excess growth rate values, we can test how well the out-of-sample simulations replicate the properties of the out-of-sample observations. \n",
    "* First, let's plot the simulated distributions versus the observed out-of-sample excess growth distributions and examine them to get a qualitative idea of how close the simulations are to the observed values. \n",
    "* Then, we'll [use the `ApproximateTwoSampleKSTest` method exported by the HypothesisTests.jl package](https://github.com/JuliaStats/HypothesisTests.jl) to compute the fraction of trials that appear to be drawn from the same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5267bdf-5231-481a-9b1d-cc862dfb539a",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we plotted the observed and simulated excess annual growth rate distribution for the out-of-sample data.\n",
    "* __Summary__: The simulated out-of-sample excess growth rate distributions (blue lines) and the observed distribution (red line) are qualitatively similar; however, the simulated distributions appear to be more heavily tailed, with more density for near-zero growth rates and broader tails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42e9aa33-9b1f-41ad-b7d0-a3855a0f2761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/jeffreyvarner/Desktop/julia_work/CHEME-130-eCornell-Repository/courses/CHEME-136/module-1/figs/Fig-HMM-GenModel-GD-OOS-SPY.pdf\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    q = plot(); \n",
    "    skip = 1000;\n",
    "    N = 1:skip:number_of_paths |> collect |> length;\n",
    "    density!(out_of_sample_decoded_archive[:,1], lw=2, c=:deepskyblue1, label=\"Simulated N = $(number_of_paths) ($(N) shown)\", \n",
    "        bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent, legend=:topleft)\n",
    "    for i ∈ 2:skip:number_of_paths\n",
    "        density!(out_of_sample_decoded_archive[:,i], lw=1, c=:deepskyblue1, label=\"\")\n",
    "    end\n",
    "    density!(out_of_sample_dataset, c=:red, lw=3, label=\"Observed\")\n",
    "    xlabel!(\"Excess growth rate daily $(ticker) (1/year)\", fontsize=18)\n",
    "    ylabel!(\"Probability Density (AU)\", fontsize=18)\n",
    "    current()\n",
    "\n",
    "    # uncomment me to save to file -\n",
    "    # savefig(joinpath(_PATH_TO_FIGS, \"Fig-HMM-GenModel-GD-OOS-$(ticker).pdf\"));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bebdd-a80c-4510-98be-29e8907ca231",
   "metadata": {},
   "source": [
    "### Check: Mean and standard deviation of the out-of-sample data\n",
    "The distributions above _look similar_ but let's dig a little deeper. For example, is the mean of out-of-sample predicted excess growth rate distribution (or the standard deviation) consistent with the observed data? Let's check if the simulated values bound the observed mean (and standard deviation) for the out-of-sample data.\n",
    "\n",
    "#### Simulated mean and standard deviation\n",
    "Compute the mean over the time dimension (rows) of the `out_of_sample_decoded_archive` array using [the Julia `mean(...)` function, where the `dim = 1` argument allows us to compute the mean over the rows](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean). This will return `number_of_paths` values for the mean (a value for each sample path), so we compute the mean over the sample paths [using the `mean(...)` function again](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean) in combination with the [Julia pipe `|>` operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping). We save the simulated sample mean as the `μ̄::Float64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c9057cd-4e21-46ae-9ee2-93ae870e1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample estimated mean: μ̄ = 0.05603502967438174\n"
     ]
    }
   ],
   "source": [
    "μ̄ = mean(out_of_sample_decoded_archive, dims=1) |> x -> mean(x);\n",
    "println(\"Out-of-sample estimated mean: μ̄ = $(μ̄)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92423b9f-e7e5-4b79-ba55-1b995e9849af",
   "metadata": {},
   "source": [
    "Similarly, we compute the expected standard deviation over time and then over the `number_of_paths` sample paths using [the `std(...)` function with the `dim = 1` argument](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.std) in combination with [the `mean(...)` function again](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean) and the [Julia pipe `|>` operator](https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping). We save the simulated sample standard deviation as the `σ̄::Float64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde5ebe8-5c46-439c-8d8c-2e7453d7897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample estimated standard deviation: σ̄ = 2.553578342668954\n"
     ]
    }
   ],
   "source": [
    "σ̄ = std(out_of_sample_decoded_archive, dims=1) |> x -> mean(x);\n",
    "println(\"Out-of-sample estimated standard deviation: σ̄ = $(σ̄)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36363c4c-b412-4895-ad1c-dafb40c77b61",
   "metadata": {},
   "source": [
    "#### Comparison with observed values\n",
    "Next, let's compute the observed mean and standard deviation values from the `out_of_sample_dataset` using the [Julia `mean(...)`](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean) and [`std(...)` functions exported by Statistics.jl](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean). Save these values in the `μ::Float64` and `σ::Float64` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46b8b22c-aff3-4688-bcfd-e2c4560ec4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = mean(out_of_sample_dataset, dims=1) |> first;\n",
    "σ = std(out_of_sample_dataset, dims=1) |> first;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0958cae-a39f-400d-bf14-6b55521cc09e",
   "metadata": {},
   "source": [
    "__Test I__: Let's test whether the observed out-of-sample excess growth rate mean is contained in a $\\pm$ `SEM` range of the mean computed over the simulations samples, i.e.., we test the condition: \n",
    "$$\n",
    "\\mu \\in R_{\\mu} \\equiv \\left[\\bar{\\mu}-\\frac{\\bar{\\sigma}}{\\sqrt{N}},\\,\\bar{\\mu}+\\frac{\\bar{\\sigma}}{\\sqrt{N}}\\right]\n",
    "$$\n",
    "using the [Julia @assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). If $\\mu\\notin{R}_{\\mu}$, i.e., the observed mean is not bounded by $\\pm$`SEM`, then an [AssertionError is thrown](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError), where `SEM` denotes the [standard error of the mean](https://en.wikipedia.org/wiki/Standard_error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "844fc150-4eb7-4897-b881-b93c9dea9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = (0.030499246247692197, 0.08157081310107128) and μ = 0.07433748620253243, μ̄ = 0.05603502967438174\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    R = (μ̄ - σ̄/√number_of_paths, μ̄ + σ̄/√number_of_paths);\n",
    "    @assert R[1] ≤ μ && μ ≤ R[2]\n",
    "    println(\"R = $(R) and μ = $(μ), μ̄ = $(μ̄)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d3c5da-a2c4-462d-bc08-e12fb467400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage difference between the observed and simulated mean is: 24.62076330949053%\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    ϵ = 100*abs(((μ - μ̄)/μ)); # percentage difference in std\n",
    "    println(\"The percentage difference between the observed and simulated mean is: $(ϵ)%\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791985bc-95c8-4557-9637-230af731d1be",
   "metadata": {},
   "source": [
    "__Test II__: Next, we'll test the simulated versus observed standard deviation of the excess growth, i.e., the volatility for the out-of-sample values. In this case, we test the conditions:\n",
    "$$\n",
    "\\sigma\\in R_{\\sigma} \\equiv \\left[\\sqrt\\frac{(N-1)\\cdot\\bar{\\sigma}^2}{\\chi_{r}^2},\\,\\sqrt{\\frac{(N-1)\\cdot\\bar{\\sigma}^2}{\\chi_{l}^2}}\\,\\right]\n",
    "$$\n",
    "using the [Julia @assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). If $\\sigma\\notin{R}_{\\sigma}$, i.e., the observed standard deviation is not bounded by $\\pm\\sqrt{(N-1)\\cdot{\\bar{\\sigma}^{2}}/\\chi_{\\star}^{2}}$, then an [AssertionError is thrown](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError), where $\\chi_{\\star}^{2}$ denotes the $\\star=\\left\\{l,r\\right\\}$ left (`l`) or right (`r`) tail of the [chi-squared distribution with $n − 1$ degrees of freedom](https://en.wikipedia.org/wiki/Chi-squared_distribution). We use [the `Chisq(...)` distribution model exported by Distributions.jl](https://github.com/JuliaStats/Distributions.jl) in combination with [the `quantile(...)` function also exported by the Distributions.jl package](https://juliastats.org/Distributions.jl/stable/univariate/#Statistics.quantile-Tuple{UnivariateDistribution,%20Real}) to compute the $\\chi_{\\star}^{2}$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a62207f-167d-4281-8267-dab043228484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For CI = 95.0%, the (χₗ,χᵣ) = (9768.525135667536,10233.748897677937)\n"
     ]
    }
   ],
   "source": [
    "α = 0.95;\n",
    "ᾱ = (1 - α);\n",
    "chi_d = Chisq(number_of_paths);\n",
    "χₗ = quantile(chi_d,ᾱ);\n",
    "χᵣ = quantile(chi_d,α);\n",
    "println(\"For CI = $(100*α)%, the (χₗ,χᵣ) = ($(χₗ),$(χᵣ))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacd842-7746-4dda-98b7-8d06c8174d1a",
   "metadata": {},
   "source": [
    "Finally, check if $\\sigma\\in{R}_{\\sigma}$ using the [Julia @assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b10df9ed-6da6-4873-81fd-1a9f0a137cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = (2.5241205477569952, 2.583526802145464) at CI = 95.0% and σ = 2.348059948742636, σ̄ = 2.553578342668954\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "AssertionError: R[1] ≤ σ && μ ≤ R[2]",
     "output_type": "error",
     "traceback": [
      "AssertionError: R[1] ≤ σ && μ ≤ R[2]",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[35]:4"
     ]
    }
   ],
   "source": [
    "let\n",
    "    R = (sqrt(((number_of_paths - 1)*σ̄^2)/(χᵣ)), sqrt(((number_of_paths - 1)*σ̄^2)/(χₗ)));\n",
    "    println(\"R = $(R) at CI = $(100*α)% and σ = $(σ), σ̄ = $(σ̄)\")\n",
    "    @assert R[1] ≤ σ && μ ≤ R[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb132eb-3852-42c5-9cd1-371652b1508c",
   "metadata": {},
   "source": [
    "__What if we fail Test II__? Currently, the model simulation fails `Test II,` i.e., the uncertainty of the standard deviation computed by the Markov model does not include the standard deviation value calculated from the out-of-sample observations (the simulated range is biased high); the standard deviation values have a percentage difference of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96d8492d-91c1-4bbd-8165-9caf2d8ace46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage difference between the observed and simulated stdev is: 8.75268938667307%\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    ϵ = 100*abs(((σ - σ̄)/σ)); # percentage difference in std\n",
    "    println(\"The percentage difference between the observed and simulated stdev is: $(ϵ)%\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a503620-7213-4232-9994-de00678ff398",
   "metadata": {},
   "source": [
    "The volatility percentage difference is less than the mean but systematically over-predicted. This suggests lower volatility in the later out-of-sample dataset compared to the in-sample data. Additionally, the range computed in `Test II` assumes a normally distributed growth rate, which is not the case. In any event, it appears that the model is over-predicting the out-of-sample volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3505ea-c0ae-4473-9ffd-e1886be7394d",
   "metadata": {},
   "source": [
    "### Check: Are the predicted and observed out-of-sample distributions the same? \n",
    "If our Markov model is correct, then the observed excess growth rate distribution and the excess growth distribution calculated by our model should look like they are drawn from the same distribution. To check this hypothesis, use [the ApproximateTwoSampleKSTest exported by the HypothesisTests.jl package](https://github.com/JuliaStats/HypothesisTests.jl) \n",
    "* `H0:null hypothesis` is that `x` and `y` are drawn from the same distribution against the `H1:alternative hypothesis` that `x` and `y` come from different distributions.\n",
    "\n",
    "We have `number_of_paths` example trajectories, so let's do the test on each sample and compute an overall expected score. Specify a `pvalue_cutoff` value to check against. If the test returns `pvalue > pvalue_cutoff,` then we fail to reject `H0:null hypothesis`, i.e., `x` and `y` appear to be drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "567bf742-acc1-4763-96c3-720f816235d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass percentage: 70.35%\n"
     ]
    }
   ],
   "source": [
    "pvalue_cutoff = 0.05; # cutoff\n",
    "pass_counter = 0;\n",
    "for i ∈ 1:number_of_paths\n",
    "    test_value = ApproximateTwoSampleKSTest(out_of_sample_dataset, out_of_sample_decoded_archive[:,i]) |> pvalue    \n",
    "    if (test_value > pvalue_cutoff)\n",
    "        pass_counter += 1 # we pass (fail to reject) x and y are from the same distribution\n",
    "    end\n",
    "end\n",
    "println(\"Pass percentage: $((pass_counter/number_of_paths)*100)%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f80c6-95f7-4be5-aee5-1eec40eb3483",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team. \n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. You should decide solely based on your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
